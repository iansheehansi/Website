{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjR9TqGqMROM"
      },
      "source": [
        "# Text2Light\n",
        "This notebook is an all-in-one inference script to generate HDR panorama from free-form texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vi172hqMROP"
      },
      "source": [
        "# Setup Environment\n",
        "This section is intended for run the script in a Colab environment. For a full local setup, we recommend to use [conda environment](https://github.com/FrozenBurning/Text2Light#Installation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dToOdsFhMhMd",
        "outputId": "6b82ded4-65cf-4f83-dc32-548166783c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep 21 13:16:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPr3BUF0QWPQ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/FrozenBurning/Text2Light\n",
        "%cd Text2Light\n",
        "!mkdir -p logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoJwamQ_MROP",
        "outputId": "01c9e41a-ebed-4f25-f502-c7cdbd043c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (5.0.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.7.6)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.9.3)\n",
            "Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.10.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.48.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 74.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.6.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install libomp-dev\n",
        "!pip install ftfy regex tqdm omegaconf pytorch-lightning tensorboardX einops transformers\n",
        "!pip install kornia\n",
        "!pip install imageio-ffmpeg\n",
        "!pip install faiss\n",
        "!pip install opencv-python==4.1.2.30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zvsi3F1MROQ"
      },
      "source": [
        "# Load model and config\n",
        "\n",
        "By default, we download our models from google drive. **However, in case that there are too many downloadings within a day, you can alternatively download model weights from onedrive.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjonpOHZMwZm",
        "outputId": "56dcad66-4c3c-4006-c111-bd29e750ec3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Text2Light/logs\n",
            "Retrieving folder list\n",
            "Retrieving folder 1d-TyBKJHSZ_gCbhZ4nB3gyViwpGEwW5S global_sampler_clip\n",
            "Retrieving folder 19Fv5cuySmDbQw4w6ejwpndojjbvWAPqJ checkpoints\n",
            "Processing file 1TcdfL-pyPrUlcMSsGuiaB6-UqTLrqDkv last.ckpt\n",
            "Retrieving folder 1YzuKkv0C3RbbPceKktI3mxPWuTcud1F- configs\n",
            "Processing file 1fjqhRYT4n1vv17y-sKwhijJIVgeVZYtb 2022-04-23T05-49-02-lightning.yaml\n",
            "Processing file 1By_DB78XDQPSR047ZuT1q4Z1zOLz7mCA 2022-04-23T05-49-02-project.yaml\n",
            "Retrieving folder 10Lwiy_c38WhC_dbKiGzQWY1dCYpd68Gc local_sampler\n",
            "Retrieving folder 1mX7AsRQfMjPvT4Bpf7R3iLPGCMVcCDFh checkpoints\n",
            "Processing file 1gEvq-TsuVxGKnABqGjfEbK0o-TQL2ovj last.ckpt\n",
            "Retrieving folder 1KqSkiWy-Yxx1qUySOf3zBWY1CbVCKBM9 configs\n",
            "Processing file 1MOsBU9XtLNEuxWCR3lWdVRulCv1bi6Mq 2022-04-17T01-29-41-lightning.yaml\n",
            "Processing file 1jBdezuWlSfFaCgERaK3znTkPWhWOcOo_ 2022-04-17T01-29-41-project.yaml\n",
            "Retrieving folder 1ppViSo6M4XLm0IP_HYyj5bbm_rcn8s-l local_sampler_indoor\n",
            "Retrieving folder 13LuKST8qOAJp0PQqHen63_8mZHcyeKij checkpoints\n",
            "Processing file 1LBu6_-gby2KP_Mh427UjVFnoh6wCZlqE last.ckpt\n",
            "Retrieving folder 1wyrVJDreZBBS0M6RVk15RQofifzUBIFT configs\n",
            "Processing file 1LWC8e2lsBhGwpVg2mePDjcV81rc69xR0 2022-04-26T13-11-31-lightning.yaml\n",
            "Processing file 1WTGbTT4NviL-hCKXUan6tpWNdnwJUjfT 2022-04-26T13-11-31-project.yaml\n",
            "Retrieving folder 1AbXwIEKWqDsNhZqSBWa7AYiVfRxw02dw local_sampler_outdoor\n",
            "Retrieving folder 1PSMdfKZ3oOD385nND3EfCp828gqKFMnN checkpoints\n",
            "Processing file 1SRDCnqp8Tb1xvlBxeqG3gh3XHLe1xwQk last.ckpt\n",
            "Retrieving folder 1NdWdOkqCKqZc7yLl6HyO6_D70X3wOrXs configs\n",
            "Processing file 1oA4zrarrJB9joygDMGjngLhjonNn1CqG 2022-04-29T20-25-45-lightning.yaml\n",
            "Processing file 1fILvvtok7XUO15kJbOt2w1IWuXVL8lL3 2022-04-29T20-25-45-project.yaml\n",
            "Processing file 1gI44jcK4fZdsmTf3Vu0_pXhLhtHhEEVz sritmo.pth\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TcdfL-pyPrUlcMSsGuiaB6-UqTLrqDkv\n",
            "To: /content/Text2Light/logs/text2light_released_model/global_sampler_clip/checkpoints/last.ckpt\n",
            "100% 1.51G/1.51G [00:08<00:00, 183MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fjqhRYT4n1vv17y-sKwhijJIVgeVZYtb\n",
            "To: /content/Text2Light/logs/text2light_released_model/global_sampler_clip/configs/2022-04-23T05-49-02-lightning.yaml\n",
            "100% 77.0/77.0 [00:00<00:00, 220kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1By_DB78XDQPSR047ZuT1q4Z1zOLz7mCA\n",
            "To: /content/Text2Light/logs/text2light_released_model/global_sampler_clip/configs/2022-04-23T05-49-02-project.yaml\n",
            "100% 1.55k/1.55k [00:00<00:00, 4.63MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gEvq-TsuVxGKnABqGjfEbK0o-TQL2ovj\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler/checkpoints/last.ckpt\n",
            "100% 1.81G/1.81G [00:06<00:00, 259MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MOsBU9XtLNEuxWCR3lWdVRulCv1bi6Mq\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler/configs/2022-04-17T01-29-41-lightning.yaml\n",
            "100% 77.0/77.0 [00:00<00:00, 232kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jBdezuWlSfFaCgERaK3znTkPWhWOcOo_\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler/configs/2022-04-17T01-29-41-project.yaml\n",
            "100% 2.12k/2.12k [00:00<00:00, 6.47MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LBu6_-gby2KP_Mh427UjVFnoh6wCZlqE\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_indoor/checkpoints/last.ckpt\n",
            "100% 1.81G/1.81G [00:39<00:00, 46.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LWC8e2lsBhGwpVg2mePDjcV81rc69xR0\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_indoor/configs/2022-04-26T13-11-31-lightning.yaml\n",
            "100% 77.0/77.0 [00:00<00:00, 183kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WTGbTT4NviL-hCKXUan6tpWNdnwJUjfT\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_indoor/configs/2022-04-26T13-11-31-project.yaml\n",
            "100% 2.13k/2.13k [00:00<00:00, 6.25MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SRDCnqp8Tb1xvlBxeqG3gh3XHLe1xwQk\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/checkpoints/last.ckpt\n",
            "100% 1.81G/1.81G [00:34<00:00, 51.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oA4zrarrJB9joygDMGjngLhjonNn1CqG\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-lightning.yaml\n",
            "100% 77.0/77.0 [00:00<00:00, 247kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fILvvtok7XUO15kJbOt2w1IWuXVL8lL3\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-project.yaml\n",
            "100% 2.13k/2.13k [00:00<00:00, 6.15MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gI44jcK4fZdsmTf3Vu0_pXhLhtHhEEVz\n",
            "To: /content/Text2Light/logs/text2light_released_model/sritmo.pth\n",
            "100% 20.5M/20.5M [00:00<00:00, 36.9MB/s]\n",
            "Download completed\n",
            "/content/Text2Light\n"
          ]
        }
      ],
      "source": [
        "%cd logs\n",
        "\n",
        "# using google drive\n",
        "!gdown --folder https://drive.google.com/drive/folders/1HKBjC7oQOzrkGFKMQmSh6PySv6AycDS3?usp=sharing\n",
        "\n",
        "# using onedrive, uncomment if download from onedrive\n",
        "# !mkdir -p text2light_released_model\n",
        "# !mkdir -p text2light_released_model/global_sampler_clip\n",
        "# !mkdir -p text2light_released_model/global_sampler_clip/checkpoints\n",
        "# !mkdir -p text2light_released_model/global_sampler_clip/configs\n",
        "# !mkdir -p text2light_released_model/local_sampler\n",
        "# !mkdir -p text2light_released_model/local_sampler/checkpoints\n",
        "# !mkdir -p text2light_released_model/local_sampler/configs\n",
        "# !mkdir -p text2light_released_model/local_sampler_indoor\n",
        "# !mkdir -p text2light_released_model/local_sampler_indoor/checkpoints\n",
        "# !mkdir -p text2light_released_model/local_sampler_indoor/configs\n",
        "# !mkdir -p text2light_released_model/local_sampler_outdoor\n",
        "# !mkdir -p text2light_released_model/local_sampler_outdoor/checkpoints\n",
        "# !mkdir -p text2light_released_model/local_sampler_outdoor/configs\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EUBiLI5EvFdBr_4fRFNeiScBflkVMSFyYwOqw-n5K8ziYA?e=by0I44&download=1\" -O text2light_released_model/global_sampler_clip/checkpoints/last.ckpt\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EYlVpiE_nJlGnGT48XrkOasBsyNhdZpo1o0kBv6GH9d3SQ?e=GnL9rZ&download=1\" -O text2light_released_model/global_sampler_clip/configs/2022-04-23T05-49-02-project.yaml\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/Ea4A8VTVNK9LsnGYpFdLMswB9l9vG1g5LGip3M7ZIIJh7Q?e=eeXqA7&download=1\" -O text2light_released_model/local_sampler/checkpoints/last.ckpt\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EaQ3yBgd4ehKpoowQHRiKRoBfG9UKetWgAv3KrbSAkyT1Q?e=UbhP4Y&download=1\" -O text2light_released_model/local_sampler/configs/2022-04-17T01-29-41-project.yaml\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EYPsy5KO71ZGphgk1YRaMAUB5EQ3GQVZwhF4QKmpASQLxg?e=fMvqU6&download=1\" -O text2light_released_model/sritmo.pth\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EceYDnnlH75GlDIpD87C6gsBq4nw98G2m1o8pzycQq23zw?e=4M30wk&download=1\" -O text2light_released_model/local_sampler_indoor/checkpoints/last.ckpt\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EWdN7JH-SN5EviwPu932v28BvX5B-4Pm10vzr0CVqRVHRA?e=3XTjD2&download=1\" -O text2light_released_model/local_sampler_indoor/configs/2022-04-26T13-11-31-project.yaml\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EUP4I6v04PtDgBlNiMCQDtkB_LKnIT9zuQ2oFAWsoXiVkg?e=CewsEE&download=1\" -O text2light_released_model/local_sampler_outdoor/checkpoints/last.ckpt\n",
        "# !wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/ERs_SkZ9f_VOoeYBk1xSC0MBkr3SHIs7rlykHKCkXxZhuA?e=hoAG4w&download=1\" -O text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-project.yaml\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_OWMFDIOtIQ"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hajNT6fSOsAq"
      },
      "outputs": [],
      "source": [
        "import argparse, os, sys, glob\n",
        "import cv2\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import clip\n",
        "from taming.util import instantiate_from_config\n",
        "from sritmo.global_sritmo import SRiTMO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Geb0BhsQiMw"
      },
      "source": [
        "# Define some utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRKG5FzQvyk"
      },
      "outputs": [],
      "source": [
        "# Ensure this cell is executed before the cell that calls `load_model`.\n",
        "def save_image(x, path):\n",
        "    c,h,w = x.shape\n",
        "    assert c==3\n",
        "    x = ((x.detach().cpu().numpy().transpose(1,2,0)+1.0)*127.5).clip(0,255).astype(np.uint8)\n",
        "    s = Image.fromarray(x)\n",
        "    s.save(path)\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_knn(database: np.array, index: faiss.Index, txt_emb, k = 5):\n",
        "    dist, idx  = index.search(txt_emb, k)\n",
        "    return database[idx], idx #[bs, k, 512]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def text2light(models: dict, prompts, outdir, params: dict):\n",
        "    # models\n",
        "    global_sampler = models[\"gs\"]\n",
        "    local_sampler = models[\"ls\"]\n",
        "    # params\n",
        "    batch_size = len(prompts)\n",
        "    top_k = params[\"top_k\"]\n",
        "    temperature = params['temperature']\n",
        "    database = params['data4knn']\n",
        "    faiss_index = params['index4knn']\n",
        "    device = params['device']\n",
        "\n",
        "    # embed input texts\n",
        "    lan_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "    lan_model.eval()\n",
        "    text = clip.tokenize(prompts).to(device)\n",
        "    text_features = lan_model.encode_text(text)\n",
        "    target_txt_emb = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "    cond, _ = get_knn(database, faiss_index, target_txt_emb.cpu().numpy().astype('float32'))\n",
        "    txt_cond = torch.from_numpy(cond.reshape(batch_size, 5, cond.shape[-1]))\n",
        "    txt_cond = torch.cat([txt_cond, txt_cond,], dim=-1).to(device)\n",
        "\n",
        "    # sample holistic condition\n",
        "    bs = batch_size\n",
        "    start = 0\n",
        "    idx = torch.zeros(bs, 1, dtype=int)[:, :start].to(device)\n",
        "    cshape = [bs, 256, 8, 16]\n",
        "    sample = True\n",
        "\n",
        "    print(\"Generating holistic conditions according to texts...\")\n",
        "    for i in tqdm(range(start, cshape[2]*cshape[3])):\n",
        "        logits, _ = global_sampler.transformer(idx, embeddings=txt_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        if top_k is not None:\n",
        "            logits = global_sampler.top_k_logits(logits, top_k)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        idx = torch.cat((idx, ix), dim=1)\n",
        "\n",
        "    xsample_holistic = global_sampler.decode_to_img(idx, cshape)\n",
        "    for i in range(xsample_holistic.shape[0]):\n",
        "        holistic_save = save_image(xsample_holistic[i], os.path.join(outdir, \"holistic\", \"holistic_[{}].png\".format(prompts[i])))\n",
        "\n",
        "    print(\"Synthesizing patches...\")\n",
        "    # synthesize patch by patch according to holistic condition\n",
        "    h = 512\n",
        "    w = 1024\n",
        "    xx, yy = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
        "    screen_points = np.stack([xx, yy], axis=-1)\n",
        "    coord = (screen_points * 2 - 1) * np.array([np.pi, np.pi/2])\n",
        "    spe = torch.from_numpy(coord).to(xsample_holistic).repeat(xsample_holistic.shape[0], 1, 1, 1).permute(0, 3, 1, 2)\n",
        "    spe = torch.nn.functional.interpolate(spe, scale_factor=1/8,\n",
        "                                            mode=\"bicubic\", recompute_scale_factor=False, align_corners=True)\n",
        "    spe = local_sampler.embedder(spe.permute(0, 2, 3, 1))\n",
        "    spe = spe.permute(0, 3, 1, 2)\n",
        "\n",
        "    _, h_indices = local_sampler.encode_to_h(xsample_holistic)\n",
        "    cshape = [xsample_holistic.shape[0], 256, h // 16, w // 16]\n",
        "    idx = torch.randint(0, 1024, (cshape[0], cshape[2], cshape[3])).to(h_indices)\n",
        "    idx = idx.reshape(cshape[0], cshape[2], cshape[3])\n",
        "\n",
        "    start = 0\n",
        "    start_i = start // cshape[3]\n",
        "    start_j = start % cshape[3]\n",
        "    sample = True\n",
        "\n",
        "    for i in tqdm(range(start_i, cshape[2])):\n",
        "        if i <= 8:\n",
        "            local_i = i\n",
        "        elif cshape[2]-i < 8:\n",
        "            local_i = 16-(cshape[2]-i)\n",
        "        else:\n",
        "            local_i = 8\n",
        "        for j in range(start_j, cshape[3]):\n",
        "            if j <= 8:\n",
        "                local_j = j\n",
        "            elif cshape[3]-j < 8:\n",
        "                local_j = 16-(cshape[3]-j)\n",
        "            else:\n",
        "                local_j = 8\n",
        "\n",
        "            i_start = i-local_i\n",
        "            i_end = i_start+16\n",
        "            j_start = j-local_j\n",
        "            j_end = j_start+16\n",
        "            patch = idx[:,i_start:i_end,j_start:j_end]\n",
        "            patch = patch.reshape(patch.shape[0],-1)\n",
        "            cpatch = spe[:, :, i_start*2:i_end*2,j_start*2:j_end*2]\n",
        "            cpatch = cpatch.reshape(cpatch.shape[0], local_sampler.cdim, -1)\n",
        "            patch = torch.cat((h_indices, patch), dim=1)\n",
        "            logits, _ = local_sampler.transformer(patch[:,:-1], embeddings=cpatch)\n",
        "            logits = logits[:, -256:, :]\n",
        "            logits = logits.reshape(cshape[0],16,16,-1)\n",
        "            logits = logits[:,local_i,local_j,:]\n",
        "            logits = logits / temperature\n",
        "\n",
        "            if top_k is not None:\n",
        "                logits = local_sampler.top_k_logits(logits, top_k)\n",
        "            # apply softmax to convert to probabilities\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            # sample from the distribution or take the most likely\n",
        "            if sample:\n",
        "                ix = torch.multinomial(probs, num_samples=1)\n",
        "            else:\n",
        "                _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "            idx[:,i,j] = ix.reshape(-1)\n",
        "    xsample = local_sampler.decode_to_img(idx, cshape)\n",
        "    for i in range(xsample.shape[0]):\n",
        "        ldr_save = save_image(xsample[i], os.path.join(outdir, \"ldr\", \"ldr_[{}].png\".format(prompts[i])))\n",
        "\n",
        "    # super-resolution inverse tone mapping\n",
        "    if params['sritmo'] is not None:\n",
        "        ldr_hr_samples, hdr_hr_samples = SRiTMO(xsample, params)\n",
        "    else:\n",
        "        print(\"no checkpoint provided, skip Stage II (SR-iTMO)...\")\n",
        "        return\n",
        "\n",
        "    for i in range(xsample.shape[0]):\n",
        "        ldr_hr_save = (ldr_hr_samples[i].permute(1, 2, 0).detach().cpu().numpy() + 1) * 127.5\n",
        "        cv2.imwrite(os.path.join(outdir, \"ldr\", \"hrldr_[{}].png\".format(prompts[i])), ldr_hr_save)\n",
        "        cv2.imwrite(os.path.join(outdir, \"hdr\", \"hdr_[{}].exr\".format(prompts[i])), hdr_hr_samples[i].permute(1, 2, 0).detach().cpu().numpy())\n",
        "    return ldr_hr_save\n",
        "\n",
        "\n",
        "def load_model_from_config(config, sd, gpu=True, eval_mode=True):\n",
        "    if \"ckpt_path\" in config.params:\n",
        "        print(\"Deleting the restore-ckpt path from the config...\")\n",
        "        config.params.ckpt_path = None\n",
        "    if \"downsample_cond_size\" in config.params:\n",
        "        print(\"Deleting downsample-cond-size from the config and setting factor=0.5 instead...\")\n",
        "        config.params.downsample_cond_size = -1\n",
        "        config.params[\"downsample_cond_factor\"] = 0.5\n",
        "    try:\n",
        "        if \"ckpt_path\" in config.params.first_stage_config.params:\n",
        "            config.params.first_stage_config.params.ckpt_path = None\n",
        "            print(\"Deleting the first-stage restore-ckpt path from the config...\")\n",
        "        if \"ckpt_path\" in config.params.cond_stage_config.params:\n",
        "            config.params.cond_stage_config.params.ckpt_path = None\n",
        "            print(\"Deleting the cond-stage restore-ckpt path from the config...\")\n",
        "        if \"ckpt_path\" in config.params.holistic_config.params:\n",
        "            config.params.holistic_config.params.ckpt_path = None\n",
        "            print(\"Deleting the global sampler restore-ckpt path from the config...\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    model = instantiate_from_config(config)\n",
        "    if sd is not None:\n",
        "        missing, unexpected = model.load_state_dict(sd, strict=False)\n",
        "        print(f\"Missing Keys in State Dict: {missing}\")\n",
        "        print(f\"Unexpected Keys in State Dict: {unexpected}\")\n",
        "    if gpu:\n",
        "        model.cuda()\n",
        "    if eval_mode:\n",
        "        model.eval()\n",
        "    return {\"model\": model}\n",
        "\n",
        "def load_model(config, ckpt, gpu, eval_mode):\n",
        "    if ckpt:\n",
        "        raw_model = torch.load(ckpt, map_location=\"cpu\")\n",
        "        state_dict = raw_model[\"state_dict\"]\n",
        "    else:\n",
        "        raise NotImplementedError(\"checkpoint at [{}] is not found!\".format(ckpt))\n",
        "    model = load_model_from_config(config.model, state_dict, gpu=gpu, eval_mode=eval_mode)[\"model\"]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ySYIWDtRAwi"
      },
      "source": [
        "# Settings for this run\n",
        "Mainly what you will have to modify will be `texts`. Please input your scene description in the text box which could be a free-form sentence. Given the limited GPU capacity of Colab, we only support generating one HDRI per inference time. To generate multiple HDRIs with a list of input texts, please refer to our [repo](https://github.com/FrozenBurning/Text2Light) for a full local installation.\n",
        "\n",
        "`model:` We use the model trained on our full dataset by default. Note that we also release models that trained on outdoor and indoor scenes respectively.\n",
        "\n",
        "`sritmo:` Specify sritmo to enable super-resolution and inverse tonemapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jk_HsuTmSFKb"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "texts = \"ocean waves crashing on shore under blue and white cloudy sky during daytime\" #@param {type:\"string\"}\n",
        "model = \"full\" #@param [\"full\", \"outdoor\", \"indoor\"]\n",
        "sritmo = True #@param {type:\"boolean\"}\n",
        "sr_factor = 4 #@param {type:\"number\"}\n",
        "top_k = 100 #@param {type:\"number\"}\n",
        "temperature = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "local_sampler_path = None\n",
        "if model == \"full\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler/\"\n",
        "elif model == \"outdoor\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler_outdoor/\"\n",
        "elif model == \"indoor\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler_indoor/\"\n",
        "else:\n",
        "  raise NotImplementedError\n",
        "\n",
        "sritmo_path = None\n",
        "if sritmo:\n",
        "  sritmo_path = \"./logs/text2light_released_model/sritmo.pth\"\n",
        "\n",
        "\n",
        "opt = argparse.Namespace(\n",
        "    resume_global=\"./logs/text2light_released_model/global_sampler_clip/\",\n",
        "    resume_local=local_sampler_path,\n",
        "    sritmo=sritmo_path,\n",
        "    sr_factor=sr_factor,\n",
        "    outdir=\"./text2light_generated\",\n",
        "    clip=\"./clip_emb.npy\",\n",
        "    text=texts,\n",
        "    top_k=top_k,\n",
        "    temperature=temperature,\n",
        "    bs=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7arlachIXBmq"
      },
      "source": [
        "# Run Text2Light!\n",
        "All outputs (including high-resolution HDR, LDR) will be saved in `./text2light_generated`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "l7h-ILKfXDzP",
        "outputId": "8d3f2364-8423-4336-b535-b20595e76a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from global sampler ckpt...\n",
            "logdir:./logs/text2light_released_model/global_sampler_clip\n",
            "./logs/text2light_released_model/global_sampler_clip/checkpoints/last.ckpt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-027de206138d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mglobal_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ],
      "source": [
        "sys.path.append(os.getcwd())\n",
        "unknown=[]\n",
        "gpu = True\n",
        "eval_mode = True\n",
        "show_config = False\n",
        "\n",
        "base = list()\n",
        "\n",
        "ckpt = None\n",
        "if opt.resume_global:\n",
        "    if not os.path.exists(opt.resume_global):\n",
        "        raise ValueError(\"Cannot find {}\".format(opt.resume_global))\n",
        "    print(\"Resuming from global sampler ckpt...\")\n",
        "    assert os.path.isdir(opt.resume_global), opt.resume_global\n",
        "    logdir = opt.resume_global.rstrip(\"/\")\n",
        "    ckpt = os.path.join(logdir, \"checkpoints\", \"last.ckpt\")\n",
        "    print(f\"logdir:{logdir}\")\n",
        "    base_configs = sorted(glob.glob(os.path.join(logdir, \"configs/*-project.yaml\")))\n",
        "    config2load = base_configs + base\n",
        "\n",
        "configs = [OmegaConf.load(cfg) for cfg in config2load]\n",
        "cli = OmegaConf.from_dotlist(unknown)\n",
        "config = OmegaConf.merge(*configs, cli)\n",
        "\n",
        "print(ckpt)\n",
        "if show_config:\n",
        "    print(OmegaConf.to_container(config))\n",
        "\n",
        "global_sampler = load_model(config, ckpt, gpu, eval_mode)\n",
        "\n",
        "ckpt = None\n",
        "if opt.resume_local:\n",
        "    if not os.path.exists(opt.resume_local):\n",
        "        raise ValueError(\"Cannot find {}\".format(opt.resume_local))\n",
        "    print(\"Resuming from local sampler ckpt...\")\n",
        "    assert os.path.isdir(opt.resume_local), opt.resume_local\n",
        "    logdir = opt.resume_local.rstrip(\"/\")\n",
        "    ckpt = os.path.join(logdir, \"checkpoints\", \"last.ckpt\")\n",
        "    print(f\"logdir:{logdir}\")\n",
        "    base_configs = sorted(glob.glob(os.path.join(logdir, \"configs/*-project.yaml\")))\n",
        "    config2load = base_configs + base\n",
        "\n",
        "configs = [OmegaConf.load(cfg) for cfg in config2load]\n",
        "cli = OmegaConf.from_dotlist(unknown)\n",
        "config = OmegaConf.merge(*configs, cli)\n",
        "print(ckpt)\n",
        "if show_config:\n",
        "    print(OmegaConf.to_container(config))\n",
        "\n",
        "local_sampler = load_model(config, ckpt, gpu, eval_mode)\n",
        "\n",
        "outdir = opt.outdir\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "print(\"Writing samples to \", outdir)\n",
        "for k in [\"holistic\", \"ldr\", \"hdr\"]:\n",
        "    os.makedirs(os.path.join(outdir, k), exist_ok=True)\n",
        "\n",
        "prompts_file = opt.text\n",
        "if os.path.exists(prompts_file):\n",
        "    # list of prompts for text2light tasks\n",
        "    with open(prompts_file, 'r') as f:\n",
        "        prompts = f.read().splitlines()\n",
        "else:\n",
        "    # a single prompt\n",
        "    prompts = [prompts_file]\n",
        "\n",
        "# construct knn searching base\n",
        "if os.path.isfile(opt.clip):\n",
        "    clip_emb = np.load(opt.clip).astype('float32')\n",
        "else:\n",
        "    raise NotImplementedError('The path [{}] to clip embedding is not valid.'.format(opt.clip))\n",
        "\n",
        "knn_index = faiss.IndexFlatIP(clip_emb.shape[-1])\n",
        "knn_index.add(clip_emb)\n",
        "\n",
        "input_models = {\n",
        "    'gs': global_sampler,\n",
        "    'ls': local_sampler,\n",
        "}\n",
        "\n",
        "input_params = {\n",
        "    'top_k': opt.top_k,\n",
        "    'temperature': opt.temperature,\n",
        "    'device': 'cuda' if gpu else 'cpu',\n",
        "    'data4knn': clip_emb,\n",
        "    'index4knn': knn_index,\n",
        "    'sritmo': opt.sritmo,\n",
        "    'sr_factor': opt.sr_factor,\n",
        "}\n",
        "for i in range(0, len(prompts), opt.bs):\n",
        "    end_i = min(len(prompts), i + opt.bs)\n",
        "    prompt = prompts[i: i+opt.bs]\n",
        "    result = text2light(input_models, prompt, outdir, input_params)\n",
        "    display(Image.fromarray(result[:, :, [2, 1, 0]].clip(0,255).astype(np.uint8)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}