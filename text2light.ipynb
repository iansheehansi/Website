{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjR9TqGqMROM"
      },
      "source": [
        "# Text2Light\n",
        "This notebook is an all-in-one inference script to generate HDR panorama from free-form texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vi172hqMROP"
      },
      "source": [
        "# Setup Environment\n",
        "This section is intended for run the script in a Colab environment. For a full local setup, we recommend to use [conda environment](https://github.com/FrozenBurning/Text2Light#Installation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dToOdsFhMhMd",
        "outputId": "30c5fc82-a0c0-4a41-cc8e-3e5691d5f283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mPr3BUF0QWPQ",
        "outputId": "a605010c-6a1b-436e-fd2f-25e6a8144a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Text2Light' already exists and is not an empty directory.\n",
            "/content/Text2Light\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/FrozenBurning/Text2Light\n",
        "%cd Text2Light\n",
        "!mkdir -p logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoJwamQ_MROP",
        "outputId": "4032f842-bbf4-461f-f9dd-5127fab4075b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connected to cloud.r-project.org (18.154\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connected to r2u.stat.i\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "--2025-06-05 11:55:56--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2279307 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py.5’\n",
            "\n",
            "get-pip.py.5        100%[===================>]   2.17M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-06-05 11:55:56 (28.6 MB/s) - ‘get-pip.py.5’ saved [2279307/2279307]\n",
            "\n",
            "Collecting pip\n",
            "  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 25.1.1\n",
            "    Uninstalling pip-25.1.1:\n",
            "      Successfully uninstalled pip-25.1.1\n",
            "Successfully installed pip-25.1.1\n",
            "Requirement already satisfied: tokenizers==0.13.3 in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Requirement already satisfied: transformers==4.30.2 in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# ✅ Namesti Python 3.10\n",
        "!apt update\n",
        "!apt install python3.10 python3.10-dev python3.10-distutils -y\n",
        "\n",
        "# ✅ Prenesi pip za Python 3.10\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3.10 get-pip.py\n",
        "\n",
        "# ✅ Uporabi virtualno okolje\n",
        "!python3.10 -m venv py310env\n",
        "!source py310env/bin/activate\n",
        "\n",
        "# ✅ Zdaj lahko uspešno namestiš tokenizers\n",
        "!pip install tokenizers==0.13.3\n",
        "!pip install transformers==4.30.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "print(\"Python path:\", sys.path)\n",
        "\n",
        "# Try to find faiss manually\n",
        "try:\n",
        "    import importlib.util\n",
        "    spec = importlib.util.find_spec(\"faiss\")\n",
        "    if spec is None:\n",
        "        print(\"faiss module not found in Python path\")\n",
        "    else:\n",
        "        print(\"faiss found at:\", spec.origin)\n",
        "except Exception as e:\n",
        "    print(\"Error checking faiss:\", e)\n",
        "\n",
        "!pip show faiss-cpu\n",
        "\n",
        "!/usr/bin/python3 -m pip install faiss-cpu --force-reinstall\n",
        "\n",
        "import sys\n",
        "print(\"Python version:\", sys.version)\n",
        "\n",
        "# Check if faiss is now available\n",
        "try:\n",
        "    import faiss\n",
        "    print(\"✅ FAISS imported successfully!\")\n",
        "    print(\"FAISS version:\", faiss.__version__ if hasattr(faiss, '__version__') else \"Unknown\")\n",
        "except ImportError as e:\n",
        "    print(\"❌ Still can't import FAISS:\", e)\n",
        "\n",
        "# !/usr/bin/python3 -m pip install faiss-cpu --force-reinstall\n",
        "#Solution 3: Try different FAISS packages\n",
        "#Sometimes the package name matters:\n",
        "#!bash!pip uninstall faiss-cpu faiss-gpu faiss -y\n",
        "#!pip install faiss-cpu==1.7.4\n",
        "#Or try the GPU version (works on CPU too):\n",
        "#bash!pip install faiss-gpu\n",
        "#Solution 4: Install from conda-forge\n",
        "#bash!pip install --extra-index-url https://download.pytorch.org/whl/cpu faiss-cpu"
      ],
      "metadata": {
        "id": "BwySBCcWohVP",
        "outputId": "8f53f1f1-76b8-41eb-cee0-01ad0e93a72e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python executable: /usr/bin/python3\n",
            "Python path: ['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor', '/root/.ipython']\n",
            "faiss found at: /usr/local/lib/python3.11/dist-packages/faiss/__init__.py\n",
            "Name: faiss-cpu\n",
            "Version: 1.11.0\n",
            "Summary: A library for efficient similarity search and clustering of dense vectors.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Kota Yamaguchi <yamaguchi_kota@cyberagent.co.jp>\n",
            "License-Expression: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, packaging\n",
            "Required-by: \n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
            "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging (from faiss-cpu)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Using cached faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: packaging, numpy, faiss-cpu\n",
            "  Attempting uninstall: packaging\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~aiss-cpu (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.63 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-cpu numpy-2.2.6 packaging-25.0\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "✅ FAISS imported successfully!\n",
            "FAISS version: 1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zvsi3F1MROQ"
      },
      "source": [
        "# Load model and config\n",
        "\n",
        "By default, we download our models from google drive. **However, in case that there are too many downloadings within a day, you can alternatively download model weights from onedrive.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjonpOHZMwZm",
        "outputId": "db03849b-cfb0-4a3f-e1f7-f7a474c7190e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Text2Light/logs\n",
            "Retrieving folder contents\n",
            "Processing file 1FeUmgi5rNr9y_HCTUJBH28XcGozZN36U sritmo.pth\n",
            "Retrieving folder 1SPOK0GVqcyW2cmO7q8DnrSgTR9VGZz43 local_sampler_outdoor\n",
            "Retrieving folder 1MzjQtYMnt09FXeWcFgdYoPAaroc15wnC checkpoints\n",
            "Processing file 1d1IeVaP6hd7AL_lKBm_ncHXoyi-1A7zc last.ckpt\n",
            "Retrieving folder 1CBeUCsWkNdBEHIaFQdThERROz9-4ZDoE configs\n",
            "Processing file 1VYbSDQmASJqDOjDTLI3wm0x1nJO30S_v 2022-04-29T20-25-45-project.yaml\n",
            "Processing file 10qkvog-f_xnZ1qLC1rLsNJsytaWBV5M- 2022-04-29T20-25-45-lightning.yaml\n",
            "Retrieving folder 1kCdzDJIjDNRFi9SLoszCdtGouZKFqbM6 local_sampler_indoor\n",
            "Retrieving folder 1seo6NX6TEezFp98x7nA4GPOFRuuQIIJd checkpoints\n",
            "Processing file 1LtBXtP1j9xuMFP7HnNobv7te-KFw-mzc last.ckpt\n",
            "Retrieving folder 15nxDKzH3bbzrmIkShynv8XVE1CT3Nz1V configs\n",
            "Processing file 1-fFHpfbYkGBdUYvRsiix5TQ8hBLS_it6 2022-04-26T13-11-31-lightning.yaml\n",
            "Processing file 1f6DECTHj7Zv_8YMTiHpgvdA8otLUi3TD 2022-04-26T13-11-31-project.yaml\n",
            "Retrieving folder 1py2RGSofhP4-A3ucC_ISF6TJAqfuxhUO global_sampler_clip\n",
            "Retrieving folder 1EKcIuHEK59CNiKED_uhopZC8ViB3t3Np configs\n",
            "Processing file 1fuFkGFYlDz8PN9l9fgEY8-UYdsTEubhb 2022-04-23T05-49-02-lightning.yaml\n",
            "Processing file 1Vt5SybEdRLeMAcv5Vc2NbUIKxeHTiTi8 2022-04-23T05-49-02-project.yaml\n",
            "Retrieving folder 1azMVIl4RlmGYiAdtKQhrdPSmF4hcoB_0 checkpoints\n",
            "Processing file 17tBfIR9O1Bj7booNmmYisQTHqb3ErzvT last.ckpt\n",
            "Retrieving folder 1nb3IFyZsYMSenZhS1U30y4sV-6IZuuf8 local_sampler\n",
            "Retrieving folder 1CrnwAMcyKYCDcUyjpkppxnvzN_qqllfH configs\n",
            "Processing file 1hnO1v1R4uFddN9aFHhimi9u1ZjsTHYLR 2022-04-17T01-29-41-lightning.yaml\n",
            "Processing file 1xbfD8ay3JKyBhafDs9jF1ZFa205dJF9u 2022-04-17T01-29-41-project.yaml\n",
            "Retrieving folder 1J3SdXsb9dKA7SHGpViJTTA1ik8DBTpTK checkpoints\n",
            "Processing file 1ULUfZkLZBrLa7VNctnzo27qoGR15N6tm last.ckpt\n",
            "Processing file 1xDiuN0ETpWm7pt7D7VwttzZ5-It3s_0M inference_pldemo_ddim100_seed.zip\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FeUmgi5rNr9y_HCTUJBH28XcGozZN36U\n",
            "To: /content/Text2Light/logs/text2light_released_model/sritmo.pth\n",
            "100% 20.5M/20.5M [00:01<00:00, 14.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1d1IeVaP6hd7AL_lKBm_ncHXoyi-1A7zc\n",
            "From (redirected): https://drive.google.com/uc?id=1d1IeVaP6hd7AL_lKBm_ncHXoyi-1A7zc&confirm=t&uuid=944af079-4a95-4605-883b-8a559437d4d6\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/checkpoints/last.ckpt\n",
            "100% 1.81G/1.81G [00:27<00:00, 66.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VYbSDQmASJqDOjDTLI3wm0x1nJO30S_v\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-project.yaml\n",
            "100% 2.13k/2.13k [00:00<00:00, 10.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10qkvog-f_xnZ1qLC1rLsNJsytaWBV5M-\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-lightning.yaml\n",
            "100% 77.0/77.0 [00:00<00:00, 395kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LtBXtP1j9xuMFP7HnNobv7te-KFw-mzc\n",
            "From (redirected): https://drive.google.com/uc?id=1LtBXtP1j9xuMFP7HnNobv7te-KFw-mzc&confirm=t&uuid=a7ce311e-e88b-4f3d-aff8-233135e6d590\n",
            "To: /content/Text2Light/logs/text2light_released_model/local_sampler_indoor/checkpoints/last.ckpt\n",
            " 66% 1.19G/1.81G [00:13<00:07, 86.7MB/s]"
          ]
        }
      ],
      "source": [
        "%cd logs\n",
        "\n",
        "# using google drive\n",
        "!gdown --folder https://drive.google.com/drive/folders/1HKBjC7oQOzrkGFKMQmSh6PySv6AycDS3?usp=sharing\n",
        "\n",
        "# using onedrive, uncomment if download from onedrive\n",
        "#!mkdir -p text2light_released_model\n",
        "#!mkdir -p text2light_released_model/global_sampler_clip\n",
        "#!mkdir -p text2light_released_model/global_sampler_clip/checkpoints\n",
        "#!mkdir -p text2light_released_model/global_sampler_clip/configs\n",
        "#!mkdir -p text2light_released_model/local_sampler\n",
        "#!mkdir -p text2light_released_model/local_sampler/checkpoints\n",
        "#!mkdir -p text2light_released_model/local_sampler/configs\n",
        "#!mkdir -p text2light_released_model/local_sampler_indoor\n",
        "#!mkdir -p text2light_released_model/local_sampler_indoor/checkpoints\n",
        "#!mkdir -p text2light_released_model/local_sampler_indoor/configs\n",
        "#!mkdir -p text2light_released_model/local_sampler_outdoor\n",
        "#!mkdir -p text2light_released_model/local_sampler_outdoor/checkpoints\n",
        "#!mkdir -p text2light_released_model/local_sampler_outdoor/configs\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EUBiLI5EvFdBr_4fRFNeiScBflkVMSFyYwOqw-n5K8ziYA?e=by0I44&download=1\" -O text2light_released_model/global_sampler_clip/checkpoints/last.ckpt\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EYlVpiE_nJlGnGT48XrkOasBsyNhdZpo1o0kBv6GH9d3SQ?e=GnL9rZ&download=1\" -O text2light_released_model/global_sampler_clip/configs/2022-04-23T05-49-02-project.yaml\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/Ea4A8VTVNK9LsnGYpFdLMswB9l9vG1g5LGip3M7ZIIJh7Q?e=eeXqA7&download=1\" -O text2light_released_model/local_sampler/checkpoints/last.ckpt\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EaQ3yBgd4ehKpoowQHRiKRoBfG9UKetWgAv3KrbSAkyT1Q?e=UbhP4Y&download=1\" -O text2light_released_model/local_sampler/configs/2022-04-17T01-29-41-project.yaml\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EYPsy5KO71ZGphgk1YRaMAUB5EQ3GQVZwhF4QKmpASQLxg?e=fMvqU6&download=1\" -O text2light_released_model/sritmo.pth\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EceYDnnlH75GlDIpD87C6gsBq4nw98G2m1o8pzycQq23zw?e=4M30wk&download=1\" -O text2light_released_model/local_sampler_indoor/checkpoints/last.ckpt\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EWdN7JH-SN5EviwPu932v28BvX5B-4Pm10vzr0CVqRVHRA?e=3XTjD2&download=1\" -O text2light_released_model/local_sampler_indoor/configs/2022-04-26T13-11-31-project.yaml\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/EUP4I6v04PtDgBlNiMCQDtkB_LKnIT9zuQ2oFAWsoXiVkg?e=CewsEE&download=1\" -O text2light_released_model/local_sampler_outdoor/checkpoints/last.ckpt\n",
        "#!wget \"https://entuedu-my.sharepoint.com/:u:/g/personal/zhaoxi001_e_ntu_edu_sg/ERs_SkZ9f_VOoeYBk1xSC0MBkr3SHIs7rlykHKCkXxZhuA?e=hoAG4w&download=1\" -O text2light_released_model/local_sampler_outdoor/configs/2022-04-29T20-25-45-project.yaml\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_OWMFDIOtIQ"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hajNT6fSOsAq"
      },
      "outputs": [],
      "source": [
        "import argparse, os, sys, glob\n",
        "import cv2\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import clip\n",
        "from taming.util import instantiate_from_config\n",
        "from sritmo.global_sritmo import SRiTMO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Geb0BhsQiMw"
      },
      "source": [
        "# Define some utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRKG5FzQvyk"
      },
      "outputs": [],
      "source": [
        "def save_image(x, path):\n",
        "    c,h,w = x.shape\n",
        "    assert c==3\n",
        "    x = ((x.detach().cpu().numpy().transpose(1,2,0)+1.0)*127.5).clip(0,255).astype(np.uint8)\n",
        "    s = Image.fromarray(x)\n",
        "    s.save(path)\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_knn(database: np.array, index: faiss.Index, txt_emb, k = 5):\n",
        "    dist, idx  = index.search(txt_emb, k)\n",
        "    return database[idx], idx #[bs, k, 512]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def text2light(models: dict, prompts, outdir, params: dict):\n",
        "    # models\n",
        "    global_sampler = models[\"gs\"]\n",
        "    local_sampler = models[\"ls\"]\n",
        "    # params\n",
        "    batch_size = len(prompts)\n",
        "    top_k = params[\"top_k\"]\n",
        "    temperature = params['temperature']\n",
        "    database = params['data4knn']\n",
        "    faiss_index = params['index4knn']\n",
        "    device = params['device']\n",
        "\n",
        "    # embed input texts\n",
        "    lan_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "    lan_model.eval()\n",
        "    text = clip.tokenize(prompts).to(device)\n",
        "    text_features = lan_model.encode_text(text)\n",
        "    target_txt_emb = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "    cond, _ = get_knn(database, faiss_index, target_txt_emb.cpu().numpy().astype('float32'))\n",
        "    txt_cond = torch.from_numpy(cond.reshape(batch_size, 5, cond.shape[-1]))\n",
        "    txt_cond = torch.cat([txt_cond, txt_cond,], dim=-1).to(device)\n",
        "\n",
        "    # sample holistic condition\n",
        "    bs = batch_size\n",
        "    start = 0\n",
        "    idx = torch.zeros(bs, 1, dtype=int)[:, :start].to(device)\n",
        "    cshape = [bs, 256, 8, 16]\n",
        "    sample = True\n",
        "\n",
        "    print(\"Generating holistic conditions according to texts...\")\n",
        "    for i in tqdm(range(start, cshape[2]*cshape[3])):\n",
        "        logits, _ = global_sampler.transformer(idx, embeddings=txt_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        if top_k is not None:\n",
        "            logits = global_sampler.top_k_logits(logits, top_k)\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        idx = torch.cat((idx, ix), dim=1)\n",
        "\n",
        "    xsample_holistic = global_sampler.decode_to_img(idx, cshape)\n",
        "    for i in range(xsample_holistic.shape[0]):\n",
        "        holistic_save = save_image(xsample_holistic[i], os.path.join(outdir, \"holistic\", \"holistic_[{}].png\".format(prompts[i])))\n",
        "\n",
        "    print(\"Synthesizing patches...\")\n",
        "    # synthesize patch by patch according to holistic condition\n",
        "    h = 512\n",
        "    w = 1024\n",
        "    xx, yy = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
        "    screen_points = np.stack([xx, yy], axis=-1)\n",
        "    coord = (screen_points * 2 - 1) * np.array([np.pi, np.pi/2])\n",
        "    spe = torch.from_numpy(coord).to(xsample_holistic).repeat(xsample_holistic.shape[0], 1, 1, 1).permute(0, 3, 1, 2)\n",
        "    spe = torch.nn.functional.interpolate(spe, scale_factor=1/8,\n",
        "                                            mode=\"bicubic\", recompute_scale_factor=False, align_corners=True)\n",
        "    spe = local_sampler.embedder(spe.permute(0, 2, 3, 1))\n",
        "    spe = spe.permute(0, 3, 1, 2)\n",
        "\n",
        "    _, h_indices = local_sampler.encode_to_h(xsample_holistic)\n",
        "    cshape = [xsample_holistic.shape[0], 256, h // 16, w // 16]\n",
        "    idx = torch.randint(0, 1024, (cshape[0], cshape[2], cshape[3])).to(h_indices)\n",
        "    idx = idx.reshape(cshape[0], cshape[2], cshape[3])\n",
        "\n",
        "    start = 0\n",
        "    start_i = start // cshape[3]\n",
        "    start_j = start % cshape[3]\n",
        "    sample = True\n",
        "\n",
        "    for i in tqdm(range(start_i, cshape[2])):\n",
        "        if i <= 8:\n",
        "            local_i = i\n",
        "        elif cshape[2]-i < 8:\n",
        "            local_i = 16-(cshape[2]-i)\n",
        "        else:\n",
        "            local_i = 8\n",
        "        for j in range(start_j, cshape[3]):\n",
        "            if j <= 8:\n",
        "                local_j = j\n",
        "            elif cshape[3]-j < 8:\n",
        "                local_j = 16-(cshape[3]-j)\n",
        "            else:\n",
        "                local_j = 8\n",
        "\n",
        "            i_start = i-local_i\n",
        "            i_end = i_start+16\n",
        "            j_start = j-local_j\n",
        "            j_end = j_start+16\n",
        "            patch = idx[:,i_start:i_end,j_start:j_end]\n",
        "            patch = patch.reshape(patch.shape[0],-1)\n",
        "            cpatch = spe[:, :, i_start*2:i_end*2,j_start*2:j_end*2]\n",
        "            cpatch = cpatch.reshape(cpatch.shape[0], local_sampler.cdim, -1)\n",
        "            patch = torch.cat((h_indices, patch), dim=1)\n",
        "            logits, _ = local_sampler.transformer(patch[:,:-1], embeddings=cpatch)\n",
        "            logits = logits[:, -256:, :]\n",
        "            logits = logits.reshape(cshape[0],16,16,-1)\n",
        "            logits = logits[:,local_i,local_j,:]\n",
        "            logits = logits / temperature\n",
        "\n",
        "            if top_k is not None:\n",
        "                logits = local_sampler.top_k_logits(logits, top_k)\n",
        "            # apply softmax to convert to probabilities\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            # sample from the distribution or take the most likely\n",
        "            if sample:\n",
        "                ix = torch.multinomial(probs, num_samples=1)\n",
        "            else:\n",
        "                _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "            idx[:,i,j] = ix.reshape(-1)\n",
        "    xsample = local_sampler.decode_to_img(idx, cshape)\n",
        "    for i in range(xsample.shape[0]):\n",
        "        ldr_save = save_image(xsample[i], os.path.join(outdir, \"ldr\", \"ldr_[{}].png\".format(prompts[i])))\n",
        "\n",
        "    # super-resolution inverse tone mapping\n",
        "    if params['sritmo'] is not None:\n",
        "        ldr_hr_samples, hdr_hr_samples = SRiTMO(xsample, params)\n",
        "    else:\n",
        "        print(\"no checkpoint provided, skip Stage II (SR-iTMO)...\")\n",
        "        return\n",
        "\n",
        "    for i in range(xsample.shape[0]):\n",
        "        ldr_hr_save = (ldr_hr_samples[i].permute(1, 2, 0).detach().cpu().numpy() + 1) * 127.5\n",
        "        cv2.imwrite(os.path.join(outdir, \"ldr\", \"hrldr_[{}].png\".format(prompts[i])), ldr_hr_save)\n",
        "        cv2.imwrite(os.path.join(outdir, \"hdr\", \"hdr_[{}].exr\".format(prompts[i])), hdr_hr_samples[i].permute(1, 2, 0).detach().cpu().numpy())\n",
        "    return ldr_hr_save\n",
        "\n",
        "\n",
        "def load_model_from_config(config, sd, gpu=True, eval_mode=True):\n",
        "    if \"ckpt_path\" in config.params:\n",
        "        print(\"Deleting the restore-ckpt path from the config...\")\n",
        "        config.params.ckpt_path = None\n",
        "    if \"downsample_cond_size\" in config.params:\n",
        "        print(\"Deleting downsample-cond-size from the config and setting factor=0.5 instead...\")\n",
        "        config.params.downsample_cond_size = -1\n",
        "        config.params[\"downsample_cond_factor\"] = 0.5\n",
        "    try:\n",
        "        if \"ckpt_path\" in config.params.first_stage_config.params:\n",
        "            config.params.first_stage_config.params.ckpt_path = None\n",
        "            print(\"Deleting the first-stage restore-ckpt path from the config...\")\n",
        "        if \"ckpt_path\" in config.params.cond_stage_config.params:\n",
        "            config.params.cond_stage_config.params.ckpt_path = None\n",
        "            print(\"Deleting the cond-stage restore-ckpt path from the config...\")\n",
        "        if \"ckpt_path\" in config.params.holistic_config.params:\n",
        "            config.params.holistic_config.params.ckpt_path = None\n",
        "            print(\"Deleting the global sampler restore-ckpt path from the config...\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    model = instantiate_from_config(config)\n",
        "    if sd is not None:\n",
        "        missing, unexpected = model.load_state_dict(sd, strict=False)\n",
        "        print(f\"Missing Keys in State Dict: {missing}\")\n",
        "        print(f\"Unexpected Keys in State Dict: {unexpected}\")\n",
        "    if gpu:\n",
        "        model.cuda()\n",
        "    if eval_mode:\n",
        "        model.eval()\n",
        "    return {\"model\": model}\n",
        "\n",
        "def load_model(config, ckpt, gpu, eval_mode):\n",
        "    if ckpt:\n",
        "        raw_model = torch.load(ckpt, map_location=\"cpu\")\n",
        "        state_dict = raw_model[\"state_dict\"]\n",
        "    else:\n",
        "        raise NotImplementedError(\"checkpoint at [{}] is not found!\".format(ckpt))\n",
        "    model = load_model_from_config(config.model, state_dict, gpu=gpu, eval_mode=eval_mode)[\"model\"]\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oFPnX9DnzxH1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ySYIWDtRAwi"
      },
      "source": [
        "# Settings for this run\n",
        "Mainly what you will have to modify will be `texts`. Please input your scene description in the text box which could be a free-form sentence. Given the limited GPU capacity of Colab, we only support generating one HDRI per inference time. To generate multiple HDRIs with a list of input texts, please refer to our [repo](https://github.com/FrozenBurning/Text2Light) for a full local installation.\n",
        "\n",
        "`model:` We use the model trained on our full dataset by default. Note that we also release models that trained on outdoor and indoor scenes respectively.\n",
        "\n",
        "`sritmo:` Specify sritmo to enable super-resolution and inverse tonemapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk_HsuTmSFKb"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "texts = \"Outer space with distant stars, colorful nebulae, and multiple planets orbiting in the vast void, illuminated by two suns casting dynamic light across the scene\" #@param {type:\"string\"}\n",
        "model = \"full\" #@param [\"full\", \"outdoor\", \"indoor\"]\n",
        "sritmo = True #@param {type:\"boolean\"}\n",
        "sr_factor = 4 #@param {type:\"number\"}\n",
        "top_k = 100 #@param {type:\"number\"}\n",
        "temperature = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "local_sampler_path = None\n",
        "if model == \"full\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler/\"\n",
        "elif model == \"outdoor\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler_outdoor/\"\n",
        "elif model == \"indoor\":\n",
        "  local_sampler_path = \"./logs/text2light_released_model/local_sampler_indoor/\"\n",
        "else:\n",
        "  raise NotImplementedError\n",
        "\n",
        "sritmo_path = None\n",
        "if sritmo:\n",
        "  sritmo_path = \"./logs/text2light_released_model/sritmo.pth\"\n",
        "\n",
        "\n",
        "opt = argparse.Namespace(\n",
        "    resume_global=\"./logs/text2light_released_model/global_sampler_clip/\",\n",
        "    resume_local=local_sampler_path,\n",
        "    sritmo=sritmo_path,\n",
        "    sr_factor=sr_factor,\n",
        "    outdir=\"./text2light_generated\",\n",
        "    clip=\"./clip_emb.npy\",\n",
        "    text=texts,\n",
        "    top_k=top_k,\n",
        "    temperature=temperature,\n",
        "    bs=1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA device count:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "ekYTVcGQ2ybK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7arlachIXBmq"
      },
      "source": [
        "# Run Text2Light!\n",
        "All outputs (including high-resolution HDR, LDR) will be saved in `./text2light_generated`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7h-ILKfXDzP"
      },
      "outputs": [],
      "source": [
        "sys.path.append(os.getcwd())\n",
        "unknown=[]\n",
        "gpu = False\n",
        "eval_mode = True\n",
        "show_config = False\n",
        "\n",
        "base = list()\n",
        "\n",
        "ckpt = None\n",
        "if opt.resume_global:\n",
        "    if not os.path.exists(opt.resume_global):\n",
        "        raise ValueError(\"Cannot find {}\".format(opt.resume_global))\n",
        "    print(\"Resuming from global sampler ckpt...\")\n",
        "    assert os.path.isdir(opt.resume_global), opt.resume_global\n",
        "    logdir = opt.resume_global.rstrip(\"/\")\n",
        "    ckpt = os.path.join(logdir, \"checkpoints\", \"last.ckpt\")\n",
        "    print(f\"logdir:{logdir}\")\n",
        "    base_configs = sorted(glob.glob(os.path.join(logdir, \"configs/*-project.yaml\")))\n",
        "    config2load = base_configs + base\n",
        "\n",
        "configs = [OmegaConf.load(cfg) for cfg in config2load]\n",
        "cli = OmegaConf.from_dotlist(unknown)\n",
        "config = OmegaConf.merge(*configs, cli)\n",
        "\n",
        "print(ckpt)\n",
        "if show_config:\n",
        "    print(OmegaConf.to_container(config))\n",
        "\n",
        "global_sampler = load_model(config, ckpt, gpu, eval_mode)\n",
        "\n",
        "ckpt = None\n",
        "if opt.resume_local:\n",
        "    if not os.path.exists(opt.resume_local):\n",
        "        raise ValueError(\"Cannot find {}\".format(opt.resume_local))\n",
        "    print(\"Resuming from local sampler ckpt...\")\n",
        "    assert os.path.isdir(opt.resume_local), opt.resume_local\n",
        "    logdir = opt.resume_local.rstrip(\"/\")\n",
        "    ckpt = os.path.join(logdir, \"checkpoints\", \"last.ckpt\")\n",
        "    print(f\"logdir:{logdir}\")\n",
        "    base_configs = sorted(glob.glob(os.path.join(logdir, \"configs/*-project.yaml\")))\n",
        "    config2load = base_configs + base\n",
        "\n",
        "configs = [OmegaConf.load(cfg) for cfg in config2load]\n",
        "cli = OmegaConf.from_dotlist(unknown)\n",
        "config = OmegaConf.merge(*configs, cli)\n",
        "print(ckpt)\n",
        "if show_config:\n",
        "    print(OmegaConf.to_container(config))\n",
        "\n",
        "local_sampler = load_model(config, ckpt, gpu, eval_mode)\n",
        "\n",
        "outdir = opt.outdir\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "print(\"Writing samples to \", outdir)\n",
        "for k in [\"holistic\", \"ldr\", \"hdr\"]:\n",
        "    os.makedirs(os.path.join(outdir, k), exist_ok=True)\n",
        "\n",
        "prompts_file = opt.text\n",
        "if os.path.exists(prompts_file):\n",
        "    # list of prompts for text2light tasks\n",
        "    with open(prompts_file, 'r') as f:\n",
        "        prompts = f.read().splitlines()\n",
        "else:\n",
        "    # a single prompt\n",
        "    prompts = [prompts_file]\n",
        "\n",
        "# construct knn searching base\n",
        "if os.path.isfile(opt.clip):\n",
        "    clip_emb = np.load(opt.clip).astype('float32')\n",
        "else:\n",
        "    raise NotImplementedError('The path [{}] to clip embedding is not valid.'.format(opt.clip))\n",
        "\n",
        "knn_index = faiss.IndexFlatIP(clip_emb.shape[-1])\n",
        "knn_index.add(clip_emb)\n",
        "\n",
        "input_models = {\n",
        "    'gs': global_sampler,\n",
        "    'ls': local_sampler,\n",
        "}\n",
        "\n",
        "input_params = {\n",
        "    'top_k': opt.top_k,\n",
        "    'temperature': opt.temperature,\n",
        "    'device': 'cuda' if gpu else 'cpu',\n",
        "    'data4knn': clip_emb,\n",
        "    'index4knn': knn_index,\n",
        "    'sritmo': opt.sritmo,\n",
        "    'sr_factor': opt.sr_factor,\n",
        "}\n",
        "for i in range(0, len(prompts), opt.bs):\n",
        "    end_i = min(len(prompts), i + opt.bs)\n",
        "    prompt = prompts[i: i+opt.bs]\n",
        "    result = text2light(input_models, prompt, outdir, input_params)\n",
        "    display(Image.fromarray(result[:, :, [2, 1, 0]].clip(0,255).astype(np.uint8)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}